import cv2
import pickle
import os
import time
import tempfile
import streamlit as st
from core.face_detection.detector import detect_faces
from core.data_collector.face_data_collector import extract_hog_features
from utils.helpers import (
    get_path,
    append_attendance_log,
    is_action_allowed,
    has_trained_data,
    display_message,
)
from utils.user_utils import is_logged_in
from core.data_collector.face_data_collector import is_good_quality


def check_prerequisites(username):
    """
    Ki·ªÉm tra c√°c ƒëi·ªÅu ki·ªán ti√™n quy·∫øt: ƒëƒÉng nh·∫≠p, d·ªØ li·ªáu khu√¥n m·∫∑t, v√† m√¥ h√¨nh nh·∫≠n di·ªán.
    - Tr·∫£ v·ªÅ: (success, message, recognizer).
    """
    if not is_logged_in():
        return False, "‚ùå Vui l√≤ng ƒëƒÉng nh·∫≠p ƒë·ªÉ th·ª±c hi·ªán h√†nh ƒë·ªông n√†y.", None

    if not username:
        return False, "‚ùå Kh√¥ng t√¨m th·∫•y username trong phi√™n ƒëƒÉng nh·∫≠p.", None

    print(f"[DEBUG] Username from session: {username}")

    if not has_trained_data(username):
        return (
            False,
            f"‚ùå D·ªØ li·ªáu khu√¥n m·∫∑t cho {username} ch∆∞a ƒë∆∞·ª£c thu th·∫≠p. Vui l√≤ng li√™n h·ªá admin.",
            None,
        )

    model_path = get_path("data/models/model.pkl")
    if not os.path.exists(model_path):
        return False, "‚ùå M√¥ h√¨nh ch∆∞a hu·∫•n luy·ªán. Vui l√≤ng li√™n h·ªá admin.", None

    try:
        with open(model_path, "rb") as f:
            recognizer = pickle.load(f)
        return True, "", recognizer
    except Exception as e:
        return False, f"‚ùå L·ªói t·∫£i m√¥ h√¨nh: {e}", None


def load_labels():
    """
    T·∫£i nh√£n t·ª´ names.pkl ƒë·ªÉ debug.
    - Tr·∫£ v·ªÅ: labels (ho·∫∑c None n·∫øu l·ªói).
    """
    names_path = get_path("data/dataset/names.pkl")
    try:
        with open(names_path, "rb") as f:
            labels = pickle.load(f)
        print(f"[DEBUG] Loaded labels: {labels}")
        return labels
    except Exception as e:
        print(f"[ERROR] Failed to load names.pkl: {e}")
        return None


def initialize_video_source(video_file):
    """
    Kh·ªüi t·∫°o ngu·ªìn video (webcam ho·∫∑c file upload).
    - Tr·∫£ v·ªÅ: (cap, temp_file_path, error_message).
    """
    cap = None
    temp_file_path = None
    start_time = time.time()  # THAY ƒê·ªîI: Th√™m log th·ªùi gian

    if video_file is None:
        for index in range(3):
            cap = cv2.VideoCapture(index)
            if cap.isOpened():
                print(f"[DEBUG] Webcam opened with index {index}")
                break
            cap.release()
        if not cap or not cap.isOpened():
            return None, None, "‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c webcam."
    else:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
            tmp.write(video_file.read())
            temp_file_path = tmp.name
        cap = cv2.VideoCapture(temp_file_path)
        if not cap.isOpened():
            return None, temp_file_path, "‚ùå Kh√¥ng th·ªÉ ƒë·ªçc file video."

    # Ki·ªÉm tra ƒë·ªô ph√¢n gi·∫£i
    ret, frame = cap.read()
    if not ret:
        print("[ERROR] Kh√¥ng th·ªÉ ƒë·ªçc khung h√¨nh t·ª´ webcam/video")
        cap.release()
        return None, temp_file_path, "‚ùå Kh√¥ng th·ªÉ ƒë·ªçc khung h√¨nh t·ª´ webcam/video"
    height, width = frame.shape[:2]
    if width < 640 or height < 480:
        print(
            f"[WARNING] ƒê·ªô ph√¢n gi·∫£i th·∫•p ({width}x{height}), c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn ph√°t hi·ªán khu√¥n m·∫∑t"
        )
    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reset v·ªÅ khung h√¨nh ƒë·∫ßu ti√™n

    print(
        f"[DEBUG] Time to initialize video source: {time.time() - start_time:.2f} seconds"
    )  # THAY ƒê·ªîI: Log th·ªùi gian
    return cap, temp_file_path, None


def process_frame_and_recognize(
    cap, recognizer, username, action, video_placeholder, video_file
):
    """
    X·ª≠ l√Ω khung h√¨nh, nh·∫≠n di·ªán khu√¥n m·∫∑t, v√† l∆∞u log ƒëi·ªÉm danh.
    - Th√™m tham s·ªë video_file ƒë·ªÉ debug ngu·ªìn video.
    - Tr·∫£ v·ªÅ: (recognized, result_message).
    """
    # THAY ƒê·ªîI: Th√™m tham s·ªë video_file ƒë·ªÉ s·ª≠ d·ª•ng trong debug
    recognized = False
    result_message = ""
    max_attempts = 10  # S·ªë khung h√¨nh t·ªëi ƒëa ƒë·ªÉ th·ª≠ nh·∫≠n di·ªán
    start_time = time.time()  # THAY ƒê·ªîI: Th√™m log th·ªùi gian

    try:
        attempt = 0
        while cap.isOpened() and not recognized and attempt < max_attempts:
            ret, frame = cap.read()
            if not ret:
                result_message = "‚ùå Kh√¥ng l·∫•y ƒë∆∞·ª£c khung h√¨nh."
                print(
                    f"[DEBUG] Failed to read frame from {'video' if video_file else 'webcam'}"
                )
                break

            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            video_placeholder.image(
                frame_rgb, caption="üîç ƒêang nh·∫≠n di·ªán...", use_container_width=True
            )

            frame_start_time = time.time()  # THAY ƒê·ªîI: Th√™m log th·ªùi gian khung h√¨nh
            faces = detect_faces(frame)
            print(f"[DEBUG] Number of faces detected: {len(faces)}")
            if len(faces) == 0:
                print("[DEBUG] No faces detected in frame")
                attempt += 1
                continue

            for x, y, w, h in faces:
                roi = frame[y : y + h, x : x + w]
                hog_features = extract_hog_features(roi, size=(100, 100))

                try:
                    name, confidence = recognizer.predict_with_confidence(hog_features)
                    print(
                        f"[DEBUG] Nh·∫≠n di·ªán: name={name}, confidence={confidence}, username={username}"
                    )

                    label = name if name == username else "unknown"
                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                    cv2.putText(
                        frame,
                        f"{label} ({confidence:.2f})",
                        (x, y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.7,
                        (0, 255, 0),
                        2,
                    )
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    video_placeholder.image(
                        frame_rgb,
                        caption="üîç ƒêang nh·∫≠n di·ªán...",
                        use_container_width=True,
                    )

                    if label == username:
                        if confidence >= 0.5:
                            if st.session_state.get("is_admin", False):
                                result_message = f"‚úÖ [DEMO] Nh·∫≠n di·ªán: {username}"
                                print(f"[DEBUG] Admin demo mode: {username}")
                                recognized = True
                                break

                            is_allowed, check_msg = is_action_allowed(username, action)
                            if not is_allowed:
                                result_message = check_msg
                                print(
                                    f"[DEBUG] is_action_allowed returned False: {check_msg}"
                                )
                                recognized = True
                                break
                            else:
                                success, msg = append_attendance_log(
                                    username, roi, "attendance", action
                                )
                                result_message = f"‚úÖ {msg}" if success else f"‚ùå {msg}"
                                print(
                                    f"[DEBUG] append_attendance_log result: success={success}, message={msg}"
                                )
                                recognized = True
                                break
                        else:
                            result_message = (
                                "‚ùå ƒê·ªô tin c·∫≠y th·∫•p. Vui l√≤ng check-in l·∫°i."
                            )
                            print(
                                f"[DEBUG] Confidence {confidence} below threshold 0.6"
                            )
                            recognized = True
                            display_message(
                                result_message,
                                is_success=True,
                                placeholder=video_placeholder,
                            )
                            break
                    else:
                        result_message = "‚ùå Khu√¥n m·∫∑t kh√¥ng x√°c ƒë·ªãnh (unknown)"
                        print(
                            f"[DEBUG] Skipping face: label={label}, not matching username={username}"
                        )
                        recognized = True
                        break

                except Exception as e:
                    print(f"[DEBUG] L·ªói nh·∫≠n di·ªán: {e}")
                    result_message = f"‚ùå L·ªói nh·∫≠n di·ªán: {e}"
                    attempt += 1
                    continue

            attempt += 1
            if cv2.waitKey(10) == 27:  # ESC ƒë·ªÉ tho√°t (ch·ªâ cho webcam)
                result_message = "‚ùå ƒê√£ h·ªßy nh·∫≠n di·ªán."
                recognized = True
                break

        if not recognized and not result_message:
            result_message = (
                "‚ùå Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c khu√¥n m·∫∑t sau nhi·ªÅu l·∫ßn th·ª≠. Vui l√≤ng th·ª≠ l·∫°i."
            )

    except Exception as e:
        result_message = f"‚ùå L·ªói trong qu√° tr√¨nh nh·∫≠n di·ªán: {e}"
        print(f"[ERROR] Exception in process_frame_and_recognize: {e}")

    print(f"[DEBUG] Total processing time: {time.time() - start_time:.2f} seconds")
    return recognized, result_message


def cleanup_video(cap, video_file, temp_file_path, video_placeholder):
    """
    D·ªçn d·∫πp t√†i nguy√™n: ƒë√≥ng video, x√≥a file t·∫°m, x√≥a placeholder.
    """
    if cap is not None:
        cap.release()
    video_placeholder.empty()
    try:
        cv2.destroyAllWindows()
    except cv2.error:
        pass  
    if video_file is not None and temp_file_path:
        try:
            os.unlink(temp_file_path)
            print(f"[DEBUG] ƒê√£ x√≥a file video t·∫°m: {temp_file_path}")
        except Exception as e:
            print(f"[ERROR] L·ªói khi x√≥a file t·∫°m: {e}")


def recognize_and_log(action="check-in", video_file=None):
    """
    Nh·∫≠n di·ªán khu√¥n m·∫∑t v√† l∆∞u log ƒëi·ªÉm danh.
    - action: H√†nh ƒë·ªông ("check-in" ho·∫∑c "check-out").
    - video_file: File video upload (n·∫øu c√≥).
    - Tr·∫£ v·ªÅ: (success, message).
    """
    username = st.session_state.get("username", None)
    success, message, recognizer = check_prerequisites(username)

    if not success:
        return False, message

    # T·∫£i nh√£n ƒë·ªÉ debug
    labels = load_labels()
    if labels is None:
        print("[DEBUG] Continuing without labels for debugging purposes")

    # Kh·ªüi t·∫°o ngu·ªìn video
    cap, temp_file_path, error_message = initialize_video_source(video_file)
    if error_message:
        return False, error_message

    # X·ª≠ l√Ω khung h√¨nh v√† nh·∫≠n di·ªán
    recognized, result_message = process_frame_and_recognize(
        cap, recognizer, username, action, st.empty(), video_file
    )

    # D·ªçn d·∫πp
    cleanup_video(cap, video_file, temp_file_path, st.empty())

    return recognized, result_message
